{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 2915)\n",
      "(3, 2915)\n",
      "(1, 2915)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for column in df.columns:\n",
    "        max_value = df[column].max()\n",
    "        min_value = df[column].min()\n",
    "        if(max_value-min_value!=0):\n",
    "            result[column] = (df[column] - min_value) / (max_value - min_value) \n",
    "        else:\n",
    "            result[column]=df[column]\n",
    "    return(result)  \n",
    "normalised_train=normalize(pd.read_csv(\"./medical_training_data.csv\"))\n",
    "normalised_test=normalize(pd.read_csv(\"./medical_testing_data.csv\"))\n",
    "\n",
    "\n",
    "normalised_train_data=np.transpose(normalised_train.iloc[:,0:16].to_numpy())\n",
    "\n",
    "\n",
    "train_result=normalised_train.iloc[:,16].to_numpy()\n",
    "train_result=np.transpose(train_result[:,np.newaxis])\n",
    "\n",
    "normalised_test_data=np.transpose(normalised_test.iloc[:,0:16].to_numpy())\n",
    "\n",
    "test_result=normalised_test.iloc[:,16].to_numpy()\n",
    "test_result=np.transpose(test_result[:,np.newaxis])\n",
    "\n",
    "class ann:\n",
    "    def __init__(self,train,train_result,test,test_result,epoches,alpha,hidden_layers,l):  # l to input the activation functions between each layer  #  hidden layers is a list passed in which number of features for each hidden layer \n",
    "        \n",
    "        self.train=train\n",
    "        self.train_result=train_result\n",
    "        self.test=test \n",
    "        self.train_result=test_result\n",
    "        self.epoches=epoches\n",
    "        self.alpha=alpha\n",
    "        self.l=l          # activation function between each rows\n",
    "\n",
    "        self.input_features=np.shape(train)[0] # along the rows \n",
    "        self.output_features = np.shape(train_result)[0]\n",
    "        self.m=np.shape(train)[1]      # along the columns in a row    \n",
    "\n",
    "        self.layers=[self.input_features]+hidden_layers+[self.output_features]   # contains number of features in each layer including start , hidden and end layers\n",
    "\n",
    "\n",
    "        weights=[]     \n",
    "        bias=[]\n",
    "         \n",
    "        \n",
    "        error_wrt_z=[]\n",
    "        error_wrt_w=[]\n",
    "        error_wrt_b=[]\n",
    "\n",
    "        for i in range(len(self.layers)-1): \n",
    "            a=np.random.rand (self.layers[i+1],self.layers[i])\n",
    "            weights.append(a)\n",
    "\n",
    "            b=np.random.rand(self.layers[i+1],1)          # will use broad casting                                              \n",
    "            bias.append(b) \n",
    "\n",
    "            error_wrt_w.append(i)    # how many dw and db will be there , later i's will be updated with dw and db matrices \n",
    "\n",
    "            error_wrt_b.append(i)      # there will be number of (layers - 1) matrices for weights,bias,error wrt w,b,z in each forward propagation   \n",
    "\n",
    "            error_wrt_z.append(i)  \n",
    "        \n",
    "        self.weights=weights\n",
    "        self.bias=bias\n",
    "\n",
    "       \n",
    "        self.error_wrt_z= error_wrt_z\n",
    "        self.error_wrt_w= error_wrt_w\n",
    "        self.error_wrt_b= error_wrt_b\n",
    "\n",
    "        self.activations=[]\n",
    "        self.z=[]\n",
    "\n",
    "        self.function_derivitive=[self.reluDerivative,self.sigmoid_derivative]  # in middle layers put relu or sigmoid only you cannnot put softmax in middle as you dont know d softmax(z) / d(z)\n",
    "        self.function=[self.relu,self.sigmoid,self.softmax]  \n",
    "\n",
    "    \n",
    "\n",
    "    def relu(self,x):\n",
    "        return np.maximum(0.0, x)\n",
    "\n",
    "\n",
    "    def sigmoid(self , x):\n",
    "        y=1/(1+np.exp(-x) )                       \n",
    "        return y\n",
    "        \n",
    "    def sigmoid_derivative(self, x):        #  d sigma(z) / d(z) = sigma(z)*(1-sigma(z)) \n",
    "        return np.multiply(x,(1-x))         # in this we are finding for all the a's of the matrix \n",
    "\n",
    "    def reluDerivative(self,x):\n",
    "        y=np.copy(x)\n",
    "        y[y<=0] = 0\n",
    "        y[y>0] = 1\n",
    "        return y     \n",
    "\n",
    "    def softmax (self,x):\n",
    "        e=np.exp(x)\n",
    "        return e/(np.sum(e,axis=0))  \n",
    "\n",
    "\n",
    "    def forward_propogate(self):\n",
    "        self.activations.clear()   #  with each epoch our w will be updated so we will be getting new activations as well as z  \n",
    "        self.z.clear()\n",
    "        self.z.append(self.train)\n",
    "        self.activations.append(self.train)        ### note z and a will contain all the layers from  1st given layer at indeex 0 to the last output predicted layer \n",
    "        for i in range (len(self.layers)-1):\n",
    "            self.z.append(np.add (np.dot(self.weights[i],self.activations[i]) ,self.bias[i]))\n",
    "        \n",
    "           # self.z.append(np.add( np.dot( self.weights[i],self.activations[i] ) ,np.repeat(self.bias[i],self.m,axis=1)) )    \n",
    "            self.activations.append(self.function[self.l[i]](self.z[i+1]  ) )     \n",
    "\n",
    "            \n",
    "a=ann(train=normalised_train_data,train_result=train_result,test=normalised_test_data,test_result=test_result,epoches=1,alpha=0.01,hidden_layers=[3],l=[1,2])\n",
    "            \n",
    "\n",
    "\n",
    "a.forward_propogate()\n",
    "for i in a.z:\n",
    "    print(i.shape)\n",
    "\n",
    "for i in a.activations:\n",
    "    print(i.shape)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ae54068e622f61d47b992eee920515c98b314ebd4be04c0239c7d903a657733"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
