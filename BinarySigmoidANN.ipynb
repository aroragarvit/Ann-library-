{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for column in df.columns:\n",
    "        max_value = df[column].max()\n",
    "        min_value = df[column].min()\n",
    "        if(max_value-min_value!=0):\n",
    "            result[column] = (df[column] - min_value) / (max_value - min_value) \n",
    "        else:\n",
    "            result[column]=df[column]\n",
    "    return(result)  \n",
    "normalised_train=normalize(pd.read_csv(\"./medical_training_data.csv\"))\n",
    "normalised_test=normalize(pd.read_csv(\"./medical_testing_data.csv\"))\n",
    "\n",
    "\n",
    "normalised_train_data=np.transpose(normalised_train.iloc[:,1:16].to_numpy())\n",
    "\n",
    "\n",
    "train_result=normalised_train.iloc[:,16].to_numpy()\n",
    "train_result=np.transpose(train_result[:,np.newaxis])\n",
    "\n",
    "normalised_test_data=np.transpose(normalised_test.iloc[:,1:16].to_numpy())\n",
    "\n",
    "test_result=normalised_test.iloc[:,16].to_numpy()\n",
    "test_result=np.transpose(test_result[:,np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in epoch 0 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 1 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 2 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 3 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 4 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 5 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 6 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 7 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 8 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 9 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 10 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 11 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 12 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 13 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 14 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 15 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 16 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 17 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 18 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 19 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 20 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 21 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 22 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 23 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 24 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 25 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 26 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 27 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 28 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 29 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 30 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 31 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 32 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 33 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 34 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 35 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 36 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 37 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 38 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 39 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 40 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 41 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 42 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 43 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 44 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 45 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 46 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 47 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 48 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 49 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 50 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 51 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 52 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 53 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 54 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 55 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 56 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 57 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 58 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 59 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 60 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 61 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 62 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 63 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 64 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 65 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 66 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 67 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 68 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 69 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 70 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 71 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 72 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 73 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 74 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 75 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 76 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 77 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 78 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 79 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 80 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 81 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 82 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 83 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 84 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 85 is 15.643224699828473 percentage\n",
      "Accuracy in epoch 86 is 15.677530017152657 percentage\n",
      "Accuracy in epoch 87 is 15.88336192109777 percentage\n",
      "Accuracy in epoch 88 is 16.843910806174957 percentage\n",
      "Accuracy in epoch 89 is 19.313893653516296 percentage\n",
      "Accuracy in epoch 90 is 22.504288164665525 percentage\n",
      "Accuracy in epoch 91 is 25.62607204116638 percentage\n",
      "Accuracy in epoch 92 is 28.610634648370496 percentage\n",
      "Accuracy in epoch 93 is 32.24699828473413 percentage\n",
      "Accuracy in epoch 94 is 36.740994854202405 percentage\n",
      "Accuracy in epoch 95 is 41.47512864493997 percentage\n",
      "Accuracy in epoch 96 is 46.92967409948542 percentage\n",
      "Accuracy in epoch 97 is 52.521440823327616 percentage\n",
      "Accuracy in epoch 98 is 57.25557461406518 percentage\n",
      "Accuracy in epoch 99 is 61.921097770154375 percentage\n",
      "Accuracy in epoch 100 is 66.00343053173242 percentage\n",
      "Accuracy in epoch 101 is 70.22298456260721 percentage\n",
      "Accuracy in epoch 102 is 74.03087478559178 percentage\n",
      "Accuracy in epoch 103 is 76.56946826758147 percentage\n",
      "Accuracy in epoch 104 is 78.8336192109777 percentage\n",
      "Accuracy in epoch 105 is 81.47512864493997 percentage\n",
      "Accuracy in epoch 106 is 83.01886792452831 percentage\n",
      "Accuracy in epoch 107 is 83.87650085763293 percentage\n",
      "Accuracy in epoch 108 is 84.18524871355059 percentage\n",
      "Accuracy in epoch 109 is 84.25385934819897 percentage\n",
      "Accuracy in epoch 110 is 84.32246998284734 percentage\n",
      "Accuracy in epoch 111 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 112 is 84.39108061749572 percentage\n",
      "Accuracy in epoch 113 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 114 is 84.39108061749572 percentage\n",
      "Accuracy in epoch 115 is 84.39108061749572 percentage\n",
      "Accuracy in epoch 116 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 117 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 118 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 119 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 120 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 121 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 122 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 123 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 124 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 125 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 126 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 127 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 128 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 129 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 130 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 131 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 132 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 133 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 134 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 135 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 136 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 137 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 138 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 139 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 140 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 141 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 142 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 143 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 144 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 145 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 146 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 147 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 148 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 149 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 150 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 151 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 152 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 153 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 154 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 155 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 156 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 157 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 158 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 159 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 160 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 161 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 162 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 163 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 164 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 165 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 166 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 167 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 168 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 169 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 170 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 171 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 172 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 173 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 174 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 175 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 176 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 177 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 178 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 179 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 180 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 181 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 182 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 183 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 184 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 185 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 186 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 187 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 188 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 189 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 190 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 191 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 192 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 193 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 194 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 195 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 196 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 197 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 198 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 199 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 200 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 201 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 202 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 203 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 204 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 205 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 206 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 207 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 208 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 209 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 210 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 211 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 212 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 213 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 214 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 215 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 216 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 217 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 218 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 219 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 220 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 221 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 222 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 223 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 224 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 225 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 226 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 227 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 228 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 229 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 230 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 231 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 232 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 233 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 234 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 235 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 236 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 237 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 238 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 239 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 240 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 241 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 242 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 243 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 244 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 245 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 246 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 247 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 248 is 84.35677530017152 percentage\n",
      "Accuracy in epoch 249 is 84.35677530017152 percentage\n",
      "accuracy percentage on your  testing data is 86.3697705802969 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class ann:\n",
    "    def __init__(self,train,train_result,test,test_result,epoches,alpha,hidden_layers,l):  # l to input the activation functions between each layer  #  hidden layers is a list passed in which number of features for each hidden layer \n",
    "        \n",
    "        self.train=train\n",
    "        self.train_result=train_result\n",
    "        self.test=test \n",
    "        self.test_result=test_result\n",
    "        self.epoches=epoches\n",
    "        self.alpha=alpha\n",
    "        self.l=l          # activation function between each rows\n",
    "\n",
    "        self.input_features=np.shape(train)[0] # along the rows \n",
    "        self.output_features = np.shape(train_result)[0]\n",
    "        self.m=np.shape(train)[1]      # along the columns in a row    \n",
    "\n",
    "        self.layers=[self.input_features]+hidden_layers+[self.output_features]   # contains number of features in each layer including start , hidden and end layers\n",
    "\n",
    "\n",
    "        weights=[]     \n",
    "        bias=[]\n",
    "         \n",
    "        \n",
    "        error_wrt_z=[]\n",
    "        error_wrt_w=[]\n",
    "        error_wrt_b=[]\n",
    "\n",
    "        for i in range(len(self.layers)-1): \n",
    "            a=np.random.rand (self.layers[i+1],self.layers[i])\n",
    "            weights.append(a)\n",
    "\n",
    "            b=np.random.rand(self.layers[i+1],1)          # will use broad casting                                              \n",
    "            bias.append(b) \n",
    "\n",
    "            error_wrt_w.append(i)    # how many dw and db will be there , later i's will be updated with dw and db matrices \n",
    "\n",
    "            error_wrt_b.append(i)      # there will be number of (layers - 1) matrices for weights,bias,error wrt w,b,z in each forward propagation   \n",
    "\n",
    "            error_wrt_z.append(i)  \n",
    "        \n",
    "        self.weights=weights\n",
    "        self.bias=bias\n",
    "\n",
    "       \n",
    "        self.error_wrt_z= error_wrt_z\n",
    "        self.error_wrt_w= error_wrt_w\n",
    "        self.error_wrt_b= error_wrt_b\n",
    "\n",
    "        self.activations=[]\n",
    "        self.z=[]\n",
    "\n",
    "        self.function_derivitive=[self.reluDerivative,self.sigmoid_derivative]  # in middle layers put relu or sigmoid only you cannnot put softmax in middle as you dont know d softmax(z) / d(z)\n",
    "        self.function=[self.relu,self.sigmoid,self.softmax]  \n",
    "\n",
    "    \n",
    "\n",
    "    def relu(self,x):\n",
    "        return np.maximum(0.0, x)\n",
    "\n",
    "\n",
    "    def sigmoid(self , x):\n",
    "        y=1/(1+np.exp(-x) )                       \n",
    "        return y\n",
    "        \n",
    "    def sigmoid_derivative(self, x):        #  d sigma(z) / d(z) = sigma(z)*(1-sigma(z)) \n",
    "        return np.multiply(x,(1-x))         # in this we are finding for all the a's of the matrix \n",
    "\n",
    "    def reluDerivative(self,x):\n",
    "        y=np.copy(x)\n",
    "        y[y<=0] = 0\n",
    "        y[y>0] = 1\n",
    "        return y     \n",
    "\n",
    "    def softmax (self,x):\n",
    "        e=np.exp(x)\n",
    "        return e/(np.sum(e,axis=0))  \n",
    "\n",
    "\n",
    "    def forward_propogate(self,data): # we are using forward prop on training as well as testing data so \n",
    "        self.activations.clear()   #  with each epoch our w will be updated as dw db dz will be updated so we will be getting new activations as well as z  after each eppoch\n",
    "        self.z.clear()\n",
    "        self.z.append(data)\n",
    "        self.activations.append(data)        ### note z and a will contain all the layers from  1st given layer at indeex 0 to the last output predicted layer \n",
    "      \n",
    "        for i in range (len(self.layers)-1):\n",
    "            self.z.append(np.add (np.dot(self.weights[i],self.activations[i]) ,self.bias[i]))\n",
    "        \n",
    "           # self.z.append(np.add( np.dot( self.weights[i],self.activations[i] ) ,np.repeat(self.bias[i],self.m,axis=1)) )    \n",
    "            self.activations.append(self.function[self.l[i]](self.z[i+1]  ) )  \n",
    "\n",
    "\n",
    "\n",
    "    def backward_propogation(self):  # we dont know d softmax(z) / d (z) so we are not using dz formula for last layer \n",
    "        self.error_wrt_z[len(self.layers)-2]=np.subtract(self.activations[len(self.layers)-1] , self.train_result )\n",
    "        for i in reversed(range(len(self.layers) - 1)):\n",
    "            self.error_wrt_w[i] = 1/self.m*(np.dot((self.error_wrt_z[i]),np.transpose(self.activations[i])))  \n",
    "            \n",
    "            self.error_wrt_b[i]=1/self.m *(np.sum(self.error_wrt_z[i] , axis=1 , keepdims=True))\n",
    "\n",
    "            if i>=1:\n",
    "                    self.error_wrt_z[i-1]=np.multiply (  np.dot ( np.transpose (self.weights[i]) , self.error_wrt_z[i] )  , self.function_derivitive[ self.l[i-1] ] ( self.function[ self.l[i-1] ]   (self.z[i]) ) )\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    def training(self):\n",
    "        for i in range(self.epoches):\n",
    "            self.forward_propogate(data=self.train)\n",
    "           \n",
    "            final_prediction=self.predict()\n",
    "            accuracy_percentage=self.accuracy(final_prediction,actual_result=self.train_result)\n",
    "            print(\"Accuracy in epoch {} is {} percentage\".format(i,accuracy_percentage))\n",
    "            self.backward_propogation()\n",
    "            for j in range(len (self.layers)-1):\n",
    "                self.weights[j]=np.subtract(self.weights[j],self.alpha*self.error_wrt_w[j])\n",
    "                \n",
    "                self.bias[j]=np.subtract(self.bias[j],self.alpha*self.error_wrt_b[j])\n",
    "    \n",
    "    def predict(self):  \n",
    "             # output is single (binary classigication using  sigmoid)   # [1 0 1 1 0 0 ] like this\n",
    "       final_prediction=0.5<=self.activations[len(self.layers)-1] \n",
    "       return(final_prediction.astype(int))    \n",
    "           \n",
    "       \n",
    "   \n",
    "    def accuracy(self,final_prediction,actual_result):\n",
    "        accuracy_per = (np.sum(actual_result ==final_prediction) / (actual_result).shape[1] ) * 100\n",
    "        return accuracy_per\n",
    "    # after training when we are having updated w  and b we predict result of testing set \n",
    "    \n",
    "    def Testing(self):\n",
    "        self.forward_propogate(data=self.test)  # we will get all activations layers including the last predicted layer \n",
    "        binary_prediction=self.predict()\n",
    "        accuracy_percentage=self.accuracy(binary_prediction,actual_result=self.test_result)\n",
    "        print(\"accuracy percentage on your  testing data is {} \".format(accuracy_percentage))\n",
    "\n",
    "\n",
    "a=ann(train=normalised_train_data,train_result=train_result,test=normalised_test_data,test_result=test_result,epoches=250,alpha=0.003,hidden_layers=[8],l=[0,1])\n",
    "\n",
    "\n",
    "a.training()\n",
    "a.Testing()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ae54068e622f61d47b992eee920515c98b314ebd4be04c0239c7d903a657733"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
